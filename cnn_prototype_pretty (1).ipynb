{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pretty_midi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mICk6PYs5W8X",
        "outputId": "04bd1f92-3808-445d-ed8c-503e6e8fcfeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretty_midi\n",
            "  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m108.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (2.0.2)\n",
            "Collecting mido>=1.1.16 (from pretty_midi)\n",
            "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pretty_midi) (1.17.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mido>=1.1.16->pretty_midi) (25.0)\n",
            "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pretty_midi\n",
            "  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592286 sha256=d821d66e11b0e87dbca43e316ae1699c574288306b3e3ec35ad5ea8b8391a945\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/95/ac/15ceaeb2823b04d8e638fd1495357adb8d26c00ccac9d7782e\n",
            "Successfully built pretty_midi\n",
            "Installing collected packages: mido, pretty_midi\n",
            "Successfully installed mido-1.3.3 pretty_midi-0.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from google.colab import drive\n",
        "import random"
      ],
      "metadata": {
        "id": "Gv4s9XY74o3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "base_path = '/content/drive/MyDrive/NEW PROJECT LIST/DL COURSE SUMMER/Group Project/Composer_Dataset/NN_midi_files_extended'\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "test_path = os.path.join(base_path, 'test')\n",
        "composers = ['bach', 'bartok', 'chopin', 'mozart']\n",
        "composer_to_idx = {composer: idx for idx, composer in enumerate(composers)}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6eOmfAe5JA8",
        "outputId": "dc0df2b7-2abe-4e96-a168-fe676aaf1589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset\n",
        "class MidiDataset(Dataset):\n",
        "    def __init__(self, file_paths, labels, transform=None):\n",
        "        self.file_paths = file_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        midi_file = self.file_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Load and preprocess MIDI\n",
        "        try:\n",
        "            midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "            piano_roll = midi_data.get_piano_roll(fs=100)  # Shape: (128, time_steps)\n",
        "\n",
        "            # Transpose to (time_steps, 128) if needed\n",
        "            piano_roll = piano_roll.T  # Shape: (time_steps, 128)\n",
        "\n",
        "            # Normalize\n",
        "            piano_roll = piano_roll / 127.0\n",
        "\n",
        "            # Pad or truncate to fixed time length (1000)\n",
        "            target_length = 1000\n",
        "            if piano_roll.shape[0] < target_length:\n",
        "                pad_width = ((0, target_length - piano_roll.shape[0]), (0, 0))\n",
        "                piano_roll = np.pad(piano_roll, pad_width, mode='constant')\n",
        "            else:\n",
        "                piano_roll = piano_roll[:target_length, :]\n",
        "\n",
        "            # Ensure pitch dimension is exactly 128\n",
        "            if piano_roll.shape[1] != 128:\n",
        "                # If pitch dimension is not 128, pad or truncate\n",
        "                if piano_roll.shape[1] < 128:\n",
        "                    pad_width = ((0, 0), (0, 128 - piano_roll.shape[1]))\n",
        "                    piano_roll = np.pad(piano_roll, pad_width, mode='constant')\n",
        "                else:\n",
        "                    piano_roll = piano_roll[:, :128]\n",
        "\n",
        "            # Add channel dimension: (1, time_steps, pitches)\n",
        "            piano_roll = np.expand_dims(piano_roll, axis=0)  # Shape: (1, 1000, 128)\n",
        "\n",
        "            # Apply data augmentation\n",
        "            if self.transform:\n",
        "                piano_roll = self.transform(piano_roll)\n",
        "\n",
        "            return torch.FloatTensor(piano_roll), torch.LongTensor([label])[0]\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {midi_file}: {e}\")\n",
        "            # Return a dummy sample if MIDI processing fails\n",
        "            return torch.zeros((1, 1000, 128)), torch.LongTensor([label])[0]"
      ],
      "metadata": {
        "id": "o1iYqAHC5FeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation functions\n",
        "def time_shift(piano_roll, max_shift=50):\n",
        "    shift = random.randint(-max_shift, max_shift)\n",
        "    return np.roll(piano_roll, shift, axis=1)\n",
        "\n",
        "def pitch_shift(piano_roll, max_shift=5):\n",
        "    shift = random.randint(-max_shift, max_shift)\n",
        "    return np.roll(piano_roll, shift, axis=2)\n",
        "\n",
        "def add_noise(piano_roll, noise_factor=0.05):\n",
        "    noise = np.random.normal(0, noise_factor, piano_roll.shape)\n",
        "    return np.clip(piano_roll + noise, 0, 1)\n",
        "\n",
        "def augment_data(piano_roll):\n",
        "    if random.random() > 0.5:\n",
        "        piano_roll = time_shift(piano_roll)\n",
        "    if random.random() > 0.5:\n",
        "        piano_roll = pitch_shift(piano_roll)\n",
        "    if random.random() > 0.5:\n",
        "        piano_roll = add_noise(piano_roll)\n",
        "    return piano_roll"
      ],
      "metadata": {
        "id": "mIfBZUXG5DI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MIDI files\n",
        "def load_midi_files(data_path):\n",
        "    file_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for composer in composers:\n",
        "        composer_path = os.path.join(data_path, composer)\n",
        "        for file in os.listdir(composer_path):\n",
        "            if file.endswith('.mid') or file.endswith('.midi'):\n",
        "                file_paths.append(os.path.join(composer_path, file))\n",
        "                labels.append(composer_to_idx[composer])\n",
        "\n",
        "    return file_paths, labels"
      ],
      "metadata": {
        "id": "NO-Nfp155A4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "class ComposerCNN(nn.Module):\n",
        "    def __init__(self, num_classes=4):\n",
        "        super(ComposerCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=(5, 5), stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=(3, 3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Calculate the size of flattened features\n",
        "        self.flatten_size = 128 * (1000 // 8) * (128 // 8)\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(self.flatten_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "k1X2uXb-4-Yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_files, train_labels = load_midi_files(train_path)\n",
        "test_files, test_labels = load_midi_files(test_path)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MidiDataset(train_files, train_labels, transform=augment_data)\n",
        "test_dataset = MidiDataset(test_files, test_labels)"
      ],
      "metadata": {
        "id": "rJhJ0GC046qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "fTAdOm-344u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ComposerCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "B5X2VqCE42hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10 #try 20\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}')"
      ],
      "metadata": {
        "id": "qrZ4Qw_14z9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e588ddd-4cb1-4fa7-be96-647ceb6508c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 65.5071\n",
            "Epoch 2/10, Loss: 38.3645\n",
            "Epoch 3/10, Loss: 36.5484\n",
            "Epoch 4/10, Loss: 20.6337\n",
            "Epoch 5/10, Loss: 11.0510\n",
            "Epoch 6/10, Loss: 16.7203\n",
            "Epoch 7/10, Loss: 7.8755\n",
            "Epoch 8/10, Loss: 7.2693\n",
            "Epoch 9/10, Loss: 9.1226\n",
            "Epoch 10/10, Loss: 6.7830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "QIXNwq2c4xdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision, recall, _, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f'\\nTest Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')"
      ],
      "metadata": {
        "id": "mxzKoy9K4rMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1cbcba-dfa4-401c-d186-83e1c59df9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Accuracy: 0.3125\n",
            "Precision: 0.3214\n",
            "Recall: 0.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}